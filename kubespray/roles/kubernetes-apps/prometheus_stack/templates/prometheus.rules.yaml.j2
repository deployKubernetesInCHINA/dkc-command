apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: kube-prometheus-stack
    release: prometheus-stack
  name: prometheus-k8s-rules
  namespace: <<prometheus_stack_namespace>>
spec:
  groups:
  - name: node-exporter.rules
    rules:
    - expr: |
        count without (cpu) (
          count without (mode) (
            node_cpu_seconds_total{job="node-exporter"}
          )
        )
      record: instance:node_num_cpu:sum
    - expr: |
        1 - avg without (cpu, mode) (
          rate(node_cpu_seconds_total{job="node-exporter", mode="idle"}[1m])
        )
      record: instance:node_cpu_utilisation:rate1m
    - expr: |
        (
          node_load1{job="node-exporter"}
        /
          instance:node_num_cpu:sum{job="node-exporter"}
        )
      record: instance:node_load1_per_cpu:ratio
    - expr: |
        1 - (
          node_memory_MemAvailable_bytes{job="node-exporter"}
        /
          node_memory_MemTotal_bytes{job="node-exporter"}
        )
      record: instance:node_memory_utilisation:ratio
    - expr: |
        rate(node_vmstat_pgmajfault{job="node-exporter"}[1m])
      record: instance:node_vmstat_pgmajfault:rate1m
    - expr: |
        rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
      record: instance_device:node_disk_io_time_seconds:rate1m
    - expr: |
        rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
      record: instance_device:node_disk_io_time_weighted_seconds:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_receive_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_transmit_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_receive_drop_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_transmit_drop_excluding_lo:rate1m
  - name: kube-apiserver.rules
    rules:
    - expr: |
        histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
  - name: k8s.rules
    rules:
    - expr: |
        sum(rate(container_cpu_usage_seconds_total{job="kubelet", image!="", container!="POD"}[5m])) by (namespace)
      record: namespace:container_cpu_usage_seconds_total:sum_rate
    - expr: |
        sum by (namespace, pod, container) (
          rate(container_cpu_usage_seconds_total{job="kubelet", image!="", container!="POD"}[5m])
        ) * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
    - expr: |
        container_memory_working_set_bytes{job="kubelet", image!=""}
        * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_working_set_bytes
    - expr: |
        container_memory_rss{job="kubelet", image!=""}
        * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_rss
    - expr: |
        container_memory_cache{job="kubelet", image!=""}
        * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_cache
    - expr: |
        container_memory_swap{job="kubelet", image!=""}
        * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_swap
    - expr: |
        sum(container_memory_usage_bytes{job="kubelet", image!="", container!="POD"}) by (namespace)
      record: namespace:container_memory_usage_bytes:sum
    - expr: |
        sum by (namespace, label_name) (
            sum(kube_pod_container_resource_requests_memory_bytes{job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod)
          * on (namespace, pod)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace:kube_pod_container_resource_requests_memory_bytes:sum
    - expr: |
        sum by (namespace, label_name) (
            sum(kube_pod_container_resource_requests_cpu_cores{job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod)
          * on (namespace, pod)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace:kube_pod_container_resource_requests_cpu_cores:sum
    - expr: |
        sum(
          label_replace(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
              "replicaset", "$1", "owner_name", "(.*)"
            ) * on(replicaset, namespace) group_left(owner_name) kube_replicaset_owner{job="kube-state-metrics"},
            "workload", "$1", "owner_name", "(.*)"
          )
        ) by (namespace, workload, pod)
      labels:
        workload_type: deployment
      record: mixin_pod_workload
    - expr: |
        sum(
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        ) by (namespace, workload, pod)
      labels:
        workload_type: daemonset
      record: mixin_pod_workload
    - expr: |
        sum(
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        ) by (namespace, workload, pod)
      labels:
        workload_type: statefulset
      record: mixin_pod_workload
  - name: kube-scheduler.rules
    rules:
    - expr: |
        histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
  - name: node.rules
    rules:
    - expr: sum(min(kube_pod_info) by (node))
      record: ':kube_pod_info_node_count:'
    - expr: |
        max(label_replace(kube_pod_info{job="kube-state-metrics"}, "pod", "$1", "pod", "(.*)")) by (node, namespace, pod)
      record: 'node_namespace_pod:kube_pod_info:'
    - expr: |
        count by (node) (sum by (node, cpu) (
          node_cpu_seconds_total{job="node-exporter"}
        * on (namespace, pod) group_left(node)
          node_namespace_pod:kube_pod_info:
        ))
      record: node:node_num_cpu:sum
    - expr: |
        sum(
          node_memory_MemAvailable_bytes{job="node-exporter"} or
          (
            node_memory_Buffers_bytes{job="node-exporter"} +
            node_memory_Cached_bytes{job="node-exporter"} +
            node_memory_MemFree_bytes{job="node-exporter"} +
            node_memory_Slab_bytes{job="node-exporter"}
          )
        )
      record: :node_memory_MemAvailable_bytes:sum
  - name: kube-prometheus-node-recording.rules
    rules:
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[3m])) BY
        (instance)
      record: instance:node_cpu:rate:sum
    - expr: sum((node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}))
        BY (instance)
      record: instance:node_filesystem_usage:sum
    - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
      record: instance:node_network_receive_bytes:rate:sum
    - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
      record: instance:node_network_transmit_bytes:rate:sum
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m])) WITHOUT
        (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total)
        BY (instance, cpu)) BY (instance)
      record: instance:node_cpu:ratio
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m]))
      record: cluster:node_cpu:sum_rate5m
    - expr: cluster:node_cpu_seconds_total:rate5m / count(sum(node_cpu_seconds_total)
        BY (instance, cpu))
      record: cluster:node_cpu:ratio
  - name: node-exporter
    rules:
    - alert: 磁盘空间使用预测
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left and is filling
          up.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 24 hours.
      expr: |
        (
          node_filesystem_avail_bytes{job=~"node-*.*",fstype!=""} / node_filesystem_size_bytes{job=~"node-*.*",fstype!=""} * 100 < 40
        and
          predict_linear(node_filesystem_avail_bytes{job=~"node-*.*",fstype!=""}[6h], 24*60*60) < 0
        and
          node_filesystem_readonly{job=~"node-*.*",fstype!=""} == 0
        )
      for: 6h
      labels:
        severity: warning
    - alert: 磁盘readonly预警
      annotations:
        description: 主机 {{ $labels.instance }} 设备{{ $labels.device }}只读, 当前值{{ $value }}
        summary: Disk read and write failure
      expr: node_filesystem_readonly{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs|udev|none|devpts|sysfs|debugfs|fuse.*",job=~"node-*.*",mountpoint!~"/var/lib/(kubelet|heketi)/.*"} == 1
      for: 60s
      labels:
        severity: critical

    - alert: 内存分配系统空间
      annotations:
        description: 主机 {{ $labels.instance }} CGroup系统空间异常,当前{{ $value | printf "%.2f" }}GB
        summary: 内存分配系统空间异常
      expr: sum by(instance) (container_memory_rss{id="/system.slice",pod_name=""}) / 1024 / 1024 / 1024 > 60 or sum by(instance) (container_memory_rss{id=~"/system.slice/.*.service"}) / 1024 / 1024 / 1024 > 60
      for: 3600s
      labels:
        severity: critical

    - alert: 主机磁盘写入速率异常
      annotations:
        description: 主机 {{ $labels.instance }}  磁盘写入速率异常,当前{{ $value | printf "%.2f" }}MB/s
        summary: 主机 {{ $labels.instance }}  磁盘写入速率异常
      expr: sum by(instance, host_group) (irate(node_disk_written_bytes_total{job=~"node-*.*"}[2m])) / 1024 / 1024 > 80
      for: 300s
      labels:
        severity: warning

    - alert: 磁盘写入耗时异常
      annotations:
        description: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 磁盘写入耗时异常,当前{{ $value }}s
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device}} 磁盘写入耗时异常
      expr: irate(node_disk_write_time_seconds_total{device=~"vd[a-z]",job=~"node-*.*"}[1m]) > 5
      for: 300s
      labels:
        severity: warning

    - alert: 磁盘读取耗时异常
      annotations:
        description: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 磁盘写入耗时异常,当前{{ $value }}s
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device}} 磁盘写入耗时异常
      expr: irate(node_disk_read_time_seconds_total{device=~"vd[a-z]",job=~"node-*.*"}[1m]) > 5
      for: 300s
      labels:
        severity: warning

    - alert: 磁盘写入IOPS异常
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘写入IOPS异常,当前{{ $value }}
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘写入IOPS耗时异常
      expr: irate(node_disk_writes_completed_total{device=~"vd[a-z]",job=~"node-*.*"}[1m]) > 1000
      for: 300s
      labels:
        severity: warning
    - alert: 磁盘读取IOPS异常
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘读取IOPS异常,当前{{ $value }}
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘读取IOPS耗时异常
      expr: irate(node_disk_reads_completed_total{device=~"vd[a-z]",job=~"node-*.*"}[1m]) > 1000
      for: 300s
      labels:
        severity: warning

    - alert: 磁盘IO耗时异常
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘IO耗时异常,当前{{ $value }}
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 磁盘IO耗时异常
      expr: irate(node_disk_io_time_seconds_total{device=~"vd[a-z]",job=~"node-*.*"}[1m]) > 10
      for: 300s
      labels:
        severity: warning

    - alert: 网卡下行流量
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 下行流量异常,速率{{ $value | printf "%.2f" }}MB/s
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 下行流量异常
      expr: irate(node_network_receive_bytes_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m]) / 1024 / 1024 > 128
      for: 300s
      labels:
        severity: info

    - alert: 网卡上行流量
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 上行流量异常,速率{{ $value | printf "%.2f" }}MB/s
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 上行流量异常
      expr: irate(node_network_transmit_bytes_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m]) / 1024 / 1024 > 128
      for: 300s
      labels:
        severity: info

    - alert: 网卡下行错误包
      annotations:
        description: 主机 {{ $labels.instance }}  设备 {{ $labels.device}} 下行数据包错误,个数{{ $value }}
        summary: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 下行数据包错误
      expr: ceil(irate(node_network_receive_errs_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m])) > 100
      for: 300s
      labels:
        severity: info

    - alert: 网卡下行丢弃包
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 下行数据包丢弃,个数{{ $value }}
        summary: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 下行数据包
      expr: ceil(irate(node_network_receive_drop_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m])) > 100
      for: 300s
      labels:
        severity: info

    - alert: 网卡上行丢弃包
      annotations:
        description: 主机 {{ $labels.instance }} 设备 {{ $labels.device }} 上行数据包丢弃,个数{{ $value }}
        summary: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 上行数据包
      expr: ceil(irate(node_network_transmit_drop_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m])) > 100
      for: 300s
      labels:
        severity: info

    - alert: 网卡上行错误包
      annotations:
        description: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 上行数据包错误,个数{{ $value }}
        summary: 主机 {{ $labels.instance }}  设备 {{ $labels.device }} 上行数据包错误
      expr: ceil(irate(node_network_transmit_errs_total{device!~"(cali.*|veth.*|kube.*|vnet.*|lo|flannel.*|docker.*|virbr.*|br.*|ovs.*|tun.*|run.*|cni.*)",job=~"node-*.*"}[1m])) > 100
      for: 300s
      labels:
        severity: info

    - alert: 进程IO阻塞
      annotations:
        description: 主机 {{ $labels.instance }} 发现阻塞进程{{ $value }}个
        summary: 主机 {{ $labels.instance }}  发现阻塞进程
      expr: node_procs_blocked{job=~"node-*.*"} > 1
      for: 60s
      labels:
        severity: info

    - alert: 活跃进程数
      annotations:
        description: 主机 {{ $labels.instance }}  活跃进程数{{ $value }}个存在风险
        summary: 主机 {{ $labels.instance }}  活跃进程数
      expr: node_procs_running{job=~"node-*.*"} > 800
      for: 300s
      labels:
        severity: critical

    - alert: 可用磁盘空间预警
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutofspace
        summary: Filesystem has less than 3% space left.
      expr: |
        (
          node_filesystem_avail_bytes{job=~"node-*.*",fstype!=""} / node_filesystem_size_bytes{job=~"node-*.*",fstype!=""} * 100 < 3
        and
          node_filesystem_readonly{job=~"node-*.*",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning

    - alert: iNode可用预警
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available inodes left.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemalmostoutoffiles
        summary: Filesystem has less than 5% inodes left.
      expr: |
        (
          node_filesystem_files_free{job=~"node-*.*",fstype!=""} / node_filesystem_files{job=~"node-*.*",fstype!=""} * 100 < 5
        and
          node_filesystem_readonly{job=~"node-*.*",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning

    - alert: Node网络接收数据错误预警
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
          {{ printf "%.0f" $value }} receive errors in the last two minutes.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworkreceiveerrs
        summary: Network interface is reporting many receive errors.
      expr: |
        increase(node_network_receive_errs_total[2m]) > 10
      for: 1h
      labels:
        severity: info

    - alert: Node网络传输错误预警
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
          {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworktransmiterrs
        summary: Network interface is reporting many transmit errors.
      expr: |
        increase(node_network_transmit_errs_total[2m]) > 10
      for: 1h
      labels:
        severity: info

  - name: kubernetes-apps
    rules:
    - alert: 容器持续CrashLooping
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
      expr: |
        rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) * 60 * 5 > 0
      for: 15m
      labels:
        severity: critical

    - alert: 主机存活监控
      annotations:
        description: 主机 {{ $labels.instance }}  失联或者node—exporter故障,状态{{ $value }}
      expr: up{job=~"node-*.*"} == 0
      for: 60s
      labels:
        severity: critical

    - alert: 主机OOM_Killer
      annotations:
        description: 主机 {{ $labels.instance }} 触发OOM_Killer
        summary: 主机触发OOM
      expr: node_vmstat_oom_kill{job=~"node-*.*"} - node_vmstat_oom_kill{job=~"node-*.*"} offset 2m > 0
      for: 60s
      labels:
        severity: critical

    - alert: CPU_IOWait使用率
      annotations:
        description: 主机 {{ $labels.instance }}  CPU_ioWait预警,当前{{ $value | printf "%.2f" }}
      expr: avg by(instance, host_group) (rate(node_cpu_seconds_total{job="node-exporter",mode="iowait"}[2m])) * 100 > 40
      for: 60s
      labels:
        severity: warning

    - alert: 容器持续Creating
      annotations:
        description:  命名空间 {{ $labels.namespace }} 容器 {{ $labels.container }} 过去15分钟处于Createing状态{{ $value }}次
      expr: kube_pod_container_status_waiting_reason{reason="ContainerCreating"} - kube_pod_container_status_waiting_reason{reason="ContainerCreating"} offset 1m > 0
      for: 15m
      labels:
        severity: critical

    - alert: 容器状态Restart
      annotations:
        description:  命名空间 {{ $labels.namespace }} 容器 {{ $labels.container }} 过去1分钟处于restart状态{{ $value }}次
      expr: kube_pod_container_status_restarts_total{job="kube-state-metrics"} - kube_pod_container_status_restarts_total{job="kube-state-metrics"} offset 1m > 0
      for: 1m
      labels:
        severity: critical

    - alert: k8s容器等待
      annotations:
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container}}
          has been in waiting state for longer than 1 hour.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
      expr: |
        sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics"}) > 0
      for: 1h
      labels:
        severity: critical

    - alert: K8sDaemonSet资源没有被调度
      annotations:
        message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
          }} are not scheduled.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
      expr: |
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          -
        kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
      for: 10m
      labels:
        severity: info

  - name: kubernetes-resources
    rules:
    - alert: K8S工作节点CPU的Requests过载
      annotations:
        message: 集群容器组对节点 {{ $labels.node }} 的内存资源 Requests 以达到 {{ printf "%.0f" $value }}%
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
      expr: |
        sum(namespace:kube_pod_container_resource_requests_cpu_cores:sum)
          /
        sum(kube_node_status_allocatable_cpu_cores)
          >
        (count(kube_node_status_allocatable_cpu_cores)-1) / count(kube_node_status_allocatable_cpu_cores)
      for: 5m
      labels:
        severity: info

    - alert: K8S工作节点平均内存Requests过载
      annotations:
        message: 集群容器组对节点 {{ $labels.node }} 的内存资源平均 Requests 以达到 {{ printf "%.0f" $value }}%，可能导致无法调度，{{ $labels.cluster }} 集群可能需要扩容
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit
      expr: |
        sum(namespace:kube_pod_container_resource_requests_memory_bytes:sum)
          /
        sum(kube_node_status_allocatable_memory_bytes)
          >
        (count(kube_node_status_allocatable_memory_bytes)-1)
          /
        count(kube_node_status_allocatable_memory_bytes)
      for: 5m
      labels:
        severity: info
    - alert: K8sApi错误预警
      annotations:
        description: API server is returning errors for {{ $value | humanizePercentage
          }} of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource
          }}.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh
      expr: |
        sum(rate(apiserver_request_total{job="apiserver",code=~"5.."}[5m])) by (resource,subresource,verb)
          /
        sum(rate(apiserver_request_total{job="apiserver"}[5m])) by (resource,subresource,verb) > 0.05
      for: 10m
      labels:
        severity: critical

    - alert: K8s客户端证书过期预警
      annotations:
        description: A client certificate used to authenticate to the apiserver is expiring in less than 30 days.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
      expr: |
        apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 2592000
      labels:
        severity: warning

    - alert: apiServer主机状态监控
      annotations:
        description: KubeAPI has disappeared from Prometheus target discovery.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
      expr: |
        absent(up{job="apiserver"} == 1)
      for: 15m
      labels:
        severity: critical

  - name: kubernetes-system-kubelet
    rules:
    - alert: KubeNode NotReady预警
      annotations:
        message: '{{ $labels.node }} has been unready for more than 15 minutes.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
      expr: |
        kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
      for: 15m
      labels:
        severity: warning

    - alert: KubeMaster不可达预警
      annotations:
        message: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable
      expr: |
        kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} == 1
      labels:
        severity: warning

    - alert: KubeletTooManyPods
      annotations:
        message: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage
          }} of its Pod capacity.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
      expr: |
        max(max(kubelet_running_pod_count{job="kubelet"}) by(instance) * on(instance) group_left(node) kubelet_node_name{job="kubelet"}) by(node) / max(kube_node_status_capacity_pods{job="kube-state-metrics"}) by(node) > 0.95
      for: 15m
      labels:
        severity: warning

    - alert: Kubelet存活预警
      annotations:
        description: Kubelet has disappeared from Prometheus target discovery.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
      expr: |
        absent(up{job="kubelet"} == 1)
      for: 15m
      labels:
        severity: critical

  - name: kubernetes-system-scheduler
    rules:
    - alert: KubeScheduler存活预警
      annotations:
        description: KubeScheduler has disappeared from Prometheus target discovery.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown
      expr: |
        absent(up{job="kube-scheduler"} == 1)
      for: 15m
      labels:
        severity: critical

  - name: kubernetes-system-controller-manager
    rules:
    - alert: KubeControllerManager存活预警
      annotations:
        description: KubeControllerManager has disappeared from Prometheus target discovery.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown
      expr: |
        absent(up{job="kube-controller-manager"} == 1)
      for: 15m
      labels:
        severity: critical

  - name: prometheus
    rules:
    - alert: Prometheus通知Alertmanager失败次数预警
      annotations:
        description: '{{ printf "%.1f" $value }}% minimum errors while sending alerts
          from Prometheus {{$labels.namespace}}/{{$labels.pod}} to any Alertmanager.'
        summary: Prometheus encounters more than 3% errors sending alerts to any Alertmanager.
      expr: |
        min without(alertmanager) (
          rate(prometheus_notifications_errors_total{job="prometheus-k8s",namespace="monitoring"}[5m])
        /
          rate(prometheus_notifications_sent_total{job="prometheus-k8s",namespace="monitoring"}[5m])
        )
        * 100
        > 3
      for: 15m
      labels:
        severity: info

    - alert: Prometheus TSDB 重载失败的次数
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
          {{$value | humanize}} reload failures over the last 3h.
        summary: Prometheus has issues reloading blocks from disk.
      expr: |
        increase(prometheus_tsdb_reloads_failures_total{job="prometheus-k8s",namespace="monitoring"}[3h]) > 0
      for: 4h
      labels:
        severity: info
    - alert: Prometheus TSDB 压缩失败的次数
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
          {{$value | humanize}} compaction failures over the last 3h.
        summary: Prometheus has issues compacting blocks.
      expr: |
        increase(prometheus_tsdb_compactions_failed_total{job="prometheus-k8s",namespace="monitoring"}[3h]) > 0
      for: 4h
      labels:
        severity: info

    - alert: Prometheus执行失败的规则次数
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to
          evaluate {{ printf "%.0f" $value }} rules in the last 5m.
        summary: Prometheus is failing rule evaluations.
      expr: |
        increase(prometheus_rule_evaluation_failures_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: info
    - alert: prometheus系统繁忙被忽略的rule执行数量
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has missed {{
          printf "%.0f" $value }} rule group evaluations in the last 5m.
        summary: Prometheus is missing rule evaluations due to slow rule group evaluation.
      expr: |
        increase(prometheus_rule_group_iterations_missed_total{job="prometheus-k8s",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: info
  - name: alertmanager.rules
    rules:
    - alert: Alertmanager重载失败
      annotations:
        message: Reloading Alertmanager's configuration has failed for {{ $labels.namespace
          }}/{{ $labels.pod}}.
      expr: |
        alertmanager_config_last_reload_successful{job="alertmanager-main",namespace="monitoring"} == 0
      for: 10m
      labels:
        severity: warning
  - name: node-time
    rules:
    - alert: 主机时间一致性预警
      annotations:
        description: Clock skew detected on node-exporter {{ $labels.namespace }}/{{ $labels.pod
          }}. Ensure NTP is configured correctly on this host.
      expr: |
        abs(node_timex_offset_seconds{job="node-exporter"}) > 0.05
      for: 2m
      labels:
        severity: critical

  - name: node-network
    rules:
    - alert: 主机网络插件运行状态预警
      annotations:
        message: Network interface "{{ $labels.device }}" changing it's up status
          often on node-exporter {{ $labels.namespace }}/{{ $labels.pod }}"
      expr: |
        changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) > 2
      for: 2m
      labels:
        severity: critical

  - name: prometheus-operator
    rules:
    - alert: cpu负载
      expr: node_load1{job="node-exporter",host_group!~"cloud.*"} > 20
      for: 5m
      labels:
        severity: critical
      annotations:
        message: 主机 {{ $labels.instance }} 负载预警,当前{{$value | printf "%.2f" }}


  - name: etcd.rules
    rules:
    - alert: Etcd集群选举异常
      annotations:
        message: etcd member {{ $labels.instance }} has no leader
        summary: etcd member has no leader
      expr: |
        etcd_server_has_leader{job="etcd"} == 0
      for: 1m
      labels:
        severity: critical

    - alert: Etcd处理提交缓慢
      annotations:
        message: etcd {{ $labels.instance }} application is slowly ,maybe etcd server is overloaded
        summary: etcd server is overloaded
      expr: (etcd_server_proposals_committed_total - etcd_server_proposals_applied_total) >= 1000
      for: 15m
      labels:
        severity: critical

        #- alert: 侦测到OOM触发行为
        #annotations:
        #message: 集群 {{ $labels.instance }} 节点侦测到 OOM 行为！
        #summary: 节点侦测到 OOM 行为
        #expr: increase(node_vmstat_oom_kill[5m]) > 0
        #for: 15m
        #labels:
        #severity: critical

    - alert: 节点内存空闲低
      annotations:
        message: 集群 {{ $labels.instance }} 节点侦测到内存使用率在 3m 内持续达到 {{ printf "%.0f" $value }}%
        summary: 节点侦测到内存使用率在降低
      expr: 100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100) > 85
      for: 3m
      labels:
        severity: critical

